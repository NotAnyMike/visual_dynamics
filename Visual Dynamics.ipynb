{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is the implementation of `Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 5 for 'Conv2D_466' (op: 'Conv2D') with input shapes: [?,64,64,32], [?,5,5,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 5 for 'Conv2D_466' (op: 'Conv2D') with input shapes: [?,64,64,32], [?,5,5,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ed7b75a17fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0mlogits_img32_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_img32_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0mcross_conv_64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_img256_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;31m#cross_conv_32 = tf.multiply(logits_img128_encoder, set2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#cross_conv_16 = tf.multiply(logits_img64_encoder, set3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    398\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corr/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 5 for 'Conv2D_466' (op: 'Conv2D') with input shapes: [?,64,64,32], [?,5,5,32]."
     ]
    }
   ],
   "source": [
    "img1 = tf.placeholder(shape=(None,256,256,3), dtype=tf.float32)\n",
    "img2 = tf.placeholder(shape=(None,256,256,3), dtype=tf.float32)\n",
    "img1_128 = tf.nn.max_pool(img1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "img2_128 = tf.nn.max_pool(img2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "img1_64 = tf.nn.max_pool(img1, ksize=[1,4,4,1], strides=[1,4,4,1], padding='VALID')\n",
    "img1_32 = tf.nn.max_pool(img1, ksize=[1,8,8,1], strides=[1,8,8,1], padding='VALID')\n",
    "\n",
    "#Motion encoder\n",
    "x1 = tf.concat([img1_128,img2_128], axis=3)\n",
    "\n",
    "#First convolution: 5x5x96\n",
    "weights = tf.Variable(tf.random_normal([5,5,6,96]))\n",
    "bias = tf.Variable(tf.zeros([96,]))\n",
    "logits = tf.nn.conv2d(x1, filter=weights, strides=[1,1,1,1], padding='SAME')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "#Second convolution: 5x5x96\n",
    "weights = tf.Variable(tf.random_normal([5,5,96,96]))\n",
    "bias = tf.Variable(tf.zeros([96,]))\n",
    "logits = tf.nn.conv2d(logits, filter=weights, strides=[1,1,1,1], padding='SAME')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.max_pool(logits, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "#Third convolution: 5x5x128\n",
    "weights = tf.Variable(tf.random_normal([5,5,96,128]))\n",
    "bias = tf.Variable(tf.zeros([128,]))\n",
    "logits = tf.nn.conv2d(logits, filter=weights, strides=[1,1,1,1], padding='SAME')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.max_pool(logits, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "#Forth convolution: 5x5x128\n",
    "weights = tf.Variable(tf.random_normal([5,5,128,128]))\n",
    "bias = tf.Variable(tf.zeros([128,]))\n",
    "logits = tf.nn.conv2d(logits, filter=weights, strides=[1,1,1,1], padding='VALID')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.max_pool(logits, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "#Fifth convolution: 5x5x256\n",
    "weights = tf.Variable(tf.random_normal([5,5,128,256]))\n",
    "bias = tf.Variable(tf.zeros([256,]))\n",
    "logits = tf.nn.conv2d(logits, filter=weights, strides=[1,1,1,1], padding='VALID')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.max_pool(logits, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "#Sixth convolution: 5x5x256\n",
    "weights = tf.Variable(tf.random_normal([5,5,256,256]))\n",
    "bias = tf.Variable(tf.zeros([256,]))\n",
    "logits = tf.nn.conv2d(logits, filter=weights, strides=[1,1,1,1], padding='SAME')\n",
    "logits = tf.add(logits, bias)\n",
    "logits = tf.nn.relu(logits)\n",
    "\n",
    "logits = tf.contrib.layers.flatten(logits)\n",
    "\n",
    "mean, variance = tf.split(logits, 2, axis=1)\n",
    "\n",
    "kernel = tf.reshape(variance, shape=[tf.shape(logits)[0],5,5,128])\n",
    "\n",
    "kernel_w = tf.Variable(tf.random_normal([5,5,128,128]))\n",
    "kernel_bias = tf.Variable(tf.random_normal([128]))\n",
    "kernel = tf.nn.conv2d(kernel, filter=kernel_w, strides=[1,1,1,1], padding='SAME')\n",
    "kernel = tf.add(kernel, kernel_bias)\n",
    "kernel = tf.nn.relu(kernel)\n",
    "\n",
    "kernel_w = tf.Variable(tf.random_normal([5,5,128,128]))\n",
    "kernel_bias = tf.Variable(tf.random_normal([128]))\n",
    "kernel = tf.nn.conv2d(kernel, filter=kernel_w, strides=[1,1,1,1], padding='SAME')\n",
    "kernel = tf.add(kernel, kernel_bias)\n",
    "kernel = tf.nn.relu(kernel)\n",
    "\n",
    "set1, set2, set3, set4 = tf.split(kernel, 4, axis=3)\n",
    "\n",
    "#Img encoder\n",
    "# for img 256x256\n",
    "logits_img256_encoder_w = tf.Variable(tf.random_normal([5,5,3,64])) \n",
    "logits_img256_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img256_encoder = tf.nn.conv2d(img1, filter=logits_img256_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img256_encoder = tf.add(logits_img256_encoder, logits_img256_encoder_b)\n",
    "logits_img256_encoder = tf.nn.relu(logits_img256_encoder)\n",
    "\n",
    "logits_img256_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img256_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img256_encoder = tf.nn.conv2d(logits_img256_encoder, filter=logits_img256_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img256_encoder = tf.add(logits_img256_encoder, logits_img256_encoder_b)\n",
    "logits_img256_encoder = tf.nn.max_pool(logits_img256_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img256_encoder = tf.nn.relu(logits_img256_encoder)\n",
    "\n",
    "logits_img256_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img256_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img256_encoder = tf.nn.conv2d(logits_img256_encoder, filter=logits_img256_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img256_encoder = tf.add(logits_img256_encoder, logits_img256_encoder_b)\n",
    "logits_img256_encoder = tf.nn.max_pool(logits_img256_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img256_encoder = tf.nn.relu(logits_img256_encoder)\n",
    "\n",
    "logits_img256_encoder_w = tf.Variable(tf.random_normal([5,5,64,32])) \n",
    "logits_img256_encoder_b = tf.Variable(tf.zeros([32]))\n",
    "logits_img256_encoder = tf.nn.conv2d(logits_img256_encoder, filter=logits_img256_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img256_encoder = tf.add(logits_img256_encoder, logits_img256_encoder_b)\n",
    "logits_img256_encoder = tf.nn.relu(logits_img256_encoder)\n",
    "\n",
    "# for img 128x128\n",
    "logits_img128_encoder_w = tf.Variable(tf.random_normal([5,5,3,64])) \n",
    "logits_img128_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img128_encoder = tf.nn.conv2d(img1_128, filter=logits_img128_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img128_encoder = tf.add(logits_img128_encoder, logits_img128_encoder_b)\n",
    "logits_img128_encoder = tf.nn.relu(logits_img128_encoder)\n",
    "\n",
    "logits_img128_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img128_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img128_encoder = tf.nn.conv2d(logits_img128_encoder, filter=logits_img128_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img128_encoder = tf.add(logits_img128_encoder, logits_img128_encoder_b)\n",
    "logits_img128_encoder = tf.nn.max_pool(logits_img128_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img128_encoder = tf.nn.relu(logits_img128_encoder)\n",
    "\n",
    "logits_img128_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img128_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img128_encoder = tf.nn.conv2d(logits_img128_encoder, filter=logits_img128_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img128_encoder = tf.add(logits_img128_encoder, logits_img128_encoder_b)\n",
    "logits_img128_encoder = tf.nn.max_pool(logits_img128_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img128_encoder = tf.nn.relu(logits_img128_encoder)\n",
    "\n",
    "logits_img128_encoder_w = tf.Variable(tf.random_normal([5,5,64,32])) \n",
    "logits_img128_encoder_b = tf.Variable(tf.zeros([32]))\n",
    "logits_img128_encoder = tf.nn.conv2d(logits_img128_encoder, filter=logits_img128_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img128_encoder = tf.add(logits_img128_encoder, logits_img128_encoder_b)\n",
    "logits_img128_encoder = tf.nn.relu(logits_img128_encoder)\n",
    "\n",
    "# for img 64x64\n",
    "logits_img64_encoder_w = tf.Variable(tf.random_normal([5,5,3,64])) \n",
    "logits_img64_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img64_encoder = tf.nn.conv2d(img1_64, filter=logits_img64_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img64_encoder = tf.add(logits_img64_encoder, logits_img64_encoder_b)\n",
    "logits_img64_encoder = tf.nn.relu(logits_img64_encoder)\n",
    "\n",
    "logits_img64_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img64_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img64_encoder = tf.nn.conv2d(logits_img64_encoder, filter=logits_img64_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img64_encoder = tf.add(logits_img64_encoder, logits_img64_encoder_b)\n",
    "logits_img64_encoder = tf.nn.max_pool(logits_img64_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img64_encoder = tf.nn.relu(logits_img64_encoder)\n",
    "\n",
    "logits_img64_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img64_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img64_encoder = tf.nn.conv2d(logits_img64_encoder, filter=logits_img64_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img64_encoder = tf.add(logits_img64_encoder, logits_img64_encoder_b)\n",
    "logits_img64_encoder = tf.nn.max_pool(logits_img64_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img64_encoder = tf.nn.relu(logits_img64_encoder)\n",
    "\n",
    "logits_img64_encoder_w = tf.Variable(tf.random_normal([5,5,64,32])) \n",
    "logits_img64_encoder_b = tf.Variable(tf.zeros([32]))\n",
    "logits_img64_encoder = tf.nn.conv2d(logits_img64_encoder, filter=logits_img64_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img64_encoder = tf.add(logits_img64_encoder, logits_img64_encoder_b)\n",
    "logits_img64_encoder = tf.nn.relu(logits_img64_encoder)\n",
    "\n",
    "# for 32x32\n",
    "logits_img32_encoder_w = tf.Variable(tf.random_normal([5,5,3,64])) \n",
    "logits_img32_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img32_encoder = tf.nn.conv2d(img1_32, filter=logits_img32_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img32_encoder = tf.add(logits_img32_encoder, logits_img32_encoder_b)\n",
    "logits_img32_encoder = tf.nn.relu(logits_img32_encoder)\n",
    "\n",
    "logits_img32_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img32_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img32_encoder = tf.nn.conv2d(logits_img32_encoder, filter=logits_img32_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img32_encoder = tf.add(logits_img32_encoder, logits_img32_encoder_b)\n",
    "logits_img32_encoder = tf.nn.max_pool(logits_img32_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img32_encoder = tf.nn.relu(logits_img32_encoder)\n",
    "\n",
    "logits_img32_encoder_w = tf.Variable(tf.random_normal([5,5,64,64])) \n",
    "logits_img32_encoder_b = tf.Variable(tf.zeros([64]))\n",
    "logits_img32_encoder = tf.nn.conv2d(logits_img32_encoder, filter=logits_img32_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img32_encoder = tf.add(logits_img32_encoder, logits_img32_encoder_b)\n",
    "logits_img32_encoder = tf.nn.max_pool(logits_img32_encoder, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "logits_img32_encoder = tf.nn.relu(logits_img32_encoder)\n",
    "\n",
    "logits_img32_encoder_w = tf.Variable(tf.random_normal([5,5,64,32])) \n",
    "logits_img32_encoder_b = tf.Variable(tf.zeros([32]))\n",
    "logits_img32_encoder = tf.nn.conv2d(logits_img32_encoder, filter=logits_img32_encoder_w, strides=[1,1,1,1], padding='SAME')\n",
    "logits_img32_encoder = tf.add(logits_img32_encoder, logits_img32_encoder_b)\n",
    "logits_img32_encoder = tf.nn.relu(logits_img32_encoder)\n",
    "\n",
    "#cross_conv_64 = tf.nn.conv2d(logits_img256_encoder, filter=set1, strides=[1,1,1,1], padding='SAME')\n",
    "#cross_conv_32 = tf.multiply(logits_img128_encoder, set2) \n",
    "#cross_conv_16 = tf.multiply(logits_img64_encoder, set3) \n",
    "#cross_conv_8 = tf.multiply(logits_img32_encoder, set4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
